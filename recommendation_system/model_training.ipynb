{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCiokfzGoJBT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import pickle\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0kxFTnMt231"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qj-XlVXKt5z3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lizlHzts5dI"
   },
   "source": [
    "## Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k11sDunkohre"
   },
   "outputs": [],
   "source": [
    "def simple_ANN_model_creation(layers=[], learning_rate = 0.001):\n",
    "\n",
    "    '''\n",
    "    The input will be a np.array of length 50, with each index representing a tag\n",
    "    The value of each index is the amount of saves that tag has received\n",
    "\n",
    "    The output will be a np.array of length 50, with each index representing a tag\n",
    "    The value of each index is either 1 or 0 indicating whether the tag should be recommended or not\n",
    "    '''\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    input_layer = tf.keras.Input(shape=(50,))\n",
    "    for layer in layers:\n",
    "        model.add(tf.keras.layers.Dense(layer, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Dense(50, activation='sigmoid'))\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss='sigmoid_cross_entropy_with_logits', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wpqp-pgzrxOB"
   },
   "outputs": [],
   "source": [
    "def train_model(X, Y, model, validation_split = 0.2, batch_size = 16, epochs = 100):\n",
    "\n",
    "  print(\"Training Model...\")\n",
    "\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    history = model.fit(\n",
    "        x = X,\n",
    "        y = Y,\n",
    "        validation_split = validation_split,\n",
    "        batch_size = batch_size,\n",
    "        epochs = epochs\n",
    "    )\n",
    "\n",
    "  print(\"best train loss: \" + str(min(history.history['loss'])) + \"\\n\" + \"best train acc: \" + str(max(history.history['accuracy'])))\n",
    "  print(\"best test loss: \" + str(min(history.history['val_loss'])) + \"\\n\" + \"best test acc: \" + str(max(history.history['val_accuracy'])))\n",
    "\n",
    "  return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2hKgUrcs-0c"
   },
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itJIZPUBtA2Q"
   },
   "outputs": [],
   "source": [
    "model = simple_ANN_model_creation([128, 128, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vG-5XJ2YtKAp"
   },
   "outputs": [],
   "source": [
    "history = train_model(X, Y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxjbLDL7tBVf"
   },
   "source": [
    "## Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g87CXM14tDqE"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
